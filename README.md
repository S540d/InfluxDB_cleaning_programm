# InfluxDB v1 Data Cleaner

Ein professionelles Tool zum AufrÃ¤umen und Konsolidieren von InfluxDB v1 Datenbanken. Dieses Tool hilft dabei, unorganisierte Messungen zu identifizieren, zu analysieren und sicher zu bereinigen.

## ğŸ¯ Problem

InfluxDB v1 Datenbanken kÃ¶nnen mit der Zeit unÃ¼bersichtlich werden:
- Messungen mit nur wenigen Datenpunkten
- Messungen, die zwischen verschiedenen Themen "gesprungen" sind
- Unlogische Anordnung und Benennung
- Verwaiste oder veraltete Messungen

## ğŸš€ LÃ¶sung

Dieses Tool bietet eine sichere, interaktive LÃ¶sung zur Datenbankbereinigung mit automatischen Backups und BestÃ¤tigungsdialogen.

## âœ¨ Features

### ğŸ” Intelligente Analyse
- **Automatische Erkennung** problematischer Messungen
- **Last Entry Tracking** - Zeigt wann zuletzt Daten geschrieben wurden
- **Datenpunkt-ZÃ¤hlung** fÃ¼r jede Messung
- **Tag- und Field-Analyse**
- **Duplikaterkennung** basierend auf Ã¤hnlichen Namen
- **Hierarchie-Visualisierung** - Tree-Ã¤hnliche Darstellung der Measurement-Beziehungen
- **Performance-Optimierung** - Parallele Verarbeitung und optimierte Abfragen

### ğŸ–¥ï¸ Benutzerfreundliche OberflÃ¤che
- **GUI-Modus** mit interaktiver Tabelle
- **Multi-Select** fÃ¼r Batch-Operationen
- **Detail-Ansicht** per Doppelklick
- **Command-Line Interface** fÃ¼r Automatisierung

### ğŸ›¡ï¸ Sicherheitsfeatures
- **Automatische Backups** vor jeder Ã„nderung
- **BestÃ¤tigungsdialoge** fÃ¼r alle kritischen Operationen
- **Detaillierte Logging** aller AktivitÃ¤ten
- **Rollback-fÃ¤hige JSON-Backups**

### ğŸ”§ Bereinigungsoperationen
- **Sichere LÃ¶schung** mit Backup und BestÃ¤tigung
- **Smart Merging** mehrerer Messungen mit Quell-Tracking
- **Bulk Cleanup** fÃ¼r Messungen mit wenigen Datenpunkten
- **Measurement Splitting** nach Tag-Werten
- **Data Aggregation** - Intelligente Komprimierung alter Daten
- **Age-based Filtering** - Zeitbasierte Bereinigung mit konfigurierbaren Schwellwerten

## ğŸ“¦ Installation

### Voraussetzungen
- Python 3.7+
- InfluxDB v1.x Server
- Tkinter (fÃ¼r GUI, meist bereits installiert)

### Setup
```bash
# Repository klonen
git clone https://github.com/S540d/InfluxDB_cleaning_programm.git
cd InfluxDB_cleaning_programm

# Virtual Environment erstellen (empfohlen)
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# oder
venv\Scripts\activate  # Windows

# Dependencies installieren
pip install -r requirements.txt
```

## ğŸ® Verwendung

### GUI Modus (Empfohlen)
```bash
python influx_cleaner.py
```

**Workflow:**
1. **Verbindung** zu InfluxDB herstellen
2. **Analyze** klicken fÃ¼r automatische Problemerkennung (optimiert mit paralleler Verarbeitung)
3. **Messungen auswÃ¤hlen** in der Tabelle
4. **GewÃ¼nschte Aktion** ausfÃ¼hren (Delete/Merge/Clean)

**Performance-Features:**
- **Parallele Analyse** mit konfigurierbaren Worker-Threads
- **Optimierte Abfragen** mit reduzierten Datenmengen
- **Live-Progress** wÃ¤hrend der Analyse
- **Smart Caching** fÃ¼r wiederholte Abfragen

### Command Line Modus
```bash
# Analyse ausgeben
python influx_cleaner.py --host localhost --port 8086 --database mydb --no-gui

# Mit verschiedenen Parametern
python influx_cleaner.py --host influxdb.example.com --port 8086 --database sensors --no-gui
```

## ğŸ“‹ GUI Bedienung

### Hauptfenster
- **Connection Panel**: InfluxDB Verbindungsparameter
- **Overview Tab**: Zusammenfassung der Analyseergebnisse
- **Measurements Tab**: Detaillierte Tabelle aller Messungen
- **Hierarchy Tab**: Tree-Darstellung der Measurement-Beziehungen

### Tabellen-Spalten
- **Measurement**: Name der Messung
- **Data Points**: Anzahl der Datenpunkte
- **Fields**: Anzahl der Fields
- **Tags**: Anzahl der Tags
- **Last Entry**: Zeitstempel des letzten Eintrags
- **Status**: Problemkategorie (OK, Low Data, Mixed Topics, Potential Duplicate)

### Aktionen
- **Delete Selected**: AusgewÃ¤hlte Messungen sicher lÃ¶schen
- **Merge Selected**: Messungen zusammenfÃ¼hren
- **Clean Low Data**: Messungen mit wenigen Datenpunkten bereinigen
- **Export Analysis**: Analyseergebnisse als JSON exportieren

**Neue Data Management Aktionen:**
- **Analyze Density**: Datenfrequenz analysieren und Aggregations-Empfehlungen erhalten
- **Aggregate Old Data**: Alte Daten zu Mittelwerten komprimieren (tÃ¤glich/wÃ¶chentlich/monatlich)
- **Filter by Age**: Daten nach Alter filtern (aggregieren oder lÃ¶schen)

### Hierarchy Tab
Die Hierarchy-Ansicht zeigt Measurements in einer baumartigen Struktur:

**Gruppierungen:**
- **Nach Namen**: Automatische Gruppierung nach gemeinsamen PrÃ¤fixen (temp_kitchen, temp_living â†’ temp/)
- **Nach Tags**: Gruppierung nach Tag-SchlÃ¼sseln und -Werten
- **Nach Themen**: Intelligente Kategorisierung (sensor, system, power, etc.)

**Navigation:**
- **Expandierbar**: Klickbare Knoten zum Auf-/Zuklappen
- **Statistiken**: Zeigt Anzahl, Gesamtpunkte und neuesten Eintrag pro Gruppe
- **Detail-Ansicht**: Doppelklick auf ğŸ“Š Symbole fÃ¼r Measurement-Details

**Nutzen:**
- Visualisiert Beziehungen zwischen Measurements
- Identifiziert logische Gruppierungen
- Hilft bei Merge-Entscheidungen
- Zeigt Naming-Patterns auf

## ğŸ“Š Data Aggregation & Filtering

### Problem lÃ¶sen: CPU-Auslastung mit zu vielen Datenpunkten

FÃ¼r Langzeit-Messungen wie CPU-Auslastung kÃ¶nnen sich Ã¼ber Jahre Millionen von Datenpunkten ansammeln. Das Tool bietet intelligente LÃ¶sungen:

**Beispiel-Workflow:**
1. **Messung auswÃ¤hlen**: z.B. "cpu_usage" mit 2.5 Mio. Datenpunkten Ã¼ber 3 Jahre
2. **Analyze Density**: Zeigt z.B. "50 points/hour - Consider daily aggregation for old data"
3. **Aggregate Old Data**: Daten Ã¤lter als 2 Jahre â†’ Tagesmittelwerte (2.5M â†’ 730 Punkte, 99.97% Reduktion)

**VerfÃ¼gbare Aggregations-Modi:**
- **Auto**: Basierend auf Datenfrequenz (empfohlen)
- **Hourly**: Stundenmittelwerte
- **Daily**: Tagesmittelwerte
- **Weekly**: Wochenmittelwerte
- **Monthly**: Monatsmittelwerte

**Smart Aggregation Logic:**
- **COUNT/SUM-Fields**: Summiert (z.B. Transaktionen)
- **MAX/MIN-Fields**: Maximum/Minimum beibehalten
- **Andere Fields**: Mittelwert (z.B. CPU, Temperatur)

**Sicherheit:**
- Automatische Backups vor Aggregation
- Originaldaten bleiben als separate Measurements verfÃ¼gbar
- Reversible Operationen durch JSON-Backups

## ğŸ”§ Konfiguration

### Verbindungsparameter
- **Host**: InfluxDB Server IP/Hostname (Standard: localhost)
- **Port**: InfluxDB Port (Standard: 8086)
- **Database**: Datenbankname
- **Username/Password**: Optional fÃ¼r authentifizierte Verbindungen

### Erweiterte Einstellungen
Die Schwellenwerte fÃ¼r problematische Messungen kÃ¶nnen im Code angepasst werden:
```python
# In influx_cleaner.py, analyze_measurement Methode
min_points = 10  # Mindestanzahl Datenpunkte
```

## ğŸ“ Projektstruktur

```
influxDB_cleaning_programm/
â”œâ”€â”€ influx_cleaner.py      # Hauptprogramm mit GUI
â”œâ”€â”€ cleaner_core.py        # Bereinigungsfunktionen
â”œâ”€â”€ requirements.txt       # Python Dependencies
â”œâ”€â”€ README.md             # Diese Datei
â”œâ”€â”€ .gitignore           # Git Ignore-Regeln
â””â”€â”€ venv/               # Virtual Environment (lokal)
```

## ğŸ”’ Sicherheit

### Backup-System
- Automatische JSON-Backups vor jeder Ã„nderung
- Zeitstempel-basierte Dateinamen
- VollstÃ¤ndige Wiederherstellbarkeit
- Backup-Dateien werden von Git ignoriert

### BestÃ¤tigungen
- Alle kritischen Operationen erfordern explizite BestÃ¤tigung
- Detaillierte Vorschau der betroffenen Messungen
- Abbruchbare Operationen

## ğŸ› Troubleshooting

### HÃ¤ufige Probleme

**"ModuleNotFoundError: No module named '_tkinter'"**
```bash
# macOS
brew install python-tk

# Ubuntu/Debian
sudo apt-get install python3-tk

# CentOS/RHEL
sudo yum install tkinter
```

**"Connection refused"**
- InfluxDB Server lÃ¤uft und ist erreichbar
- Firewall-Einstellungen prÃ¼fen
- Korrekte Host/Port-Parameter

**"Database not found"**
- Datenbankname korrekt eingeben
- Benutzerrechte fÃ¼r Datenbank prÃ¼fen

## ğŸ¤ Entwicklung

### Code-Struktur
- `InfluxDBAnalyzer`: Datenbank-Analyse und -Verbindung
- `InfluxDBCleaner`: Bereinigungsoperationen
- `InfluxCleanerGUI`: Grafische BenutzeroberflÃ¤che

### Beitragen
1. Fork des Repositories
2. Feature-Branch erstellen
3. Ã„nderungen implementieren
4. Tests hinzufÃ¼gen
5. Pull Request erstellen

## ğŸ“„ Lizenz

MIT License - Siehe LICENSE Datei fÃ¼r Details

## âš ï¸ Haftungsausschluss

Dieses Tool fÃ¼hrt Schreiboperationen auf InfluxDB-Datenbanken aus. Obwohl automatische Backups erstellt werden, wird empfohlen, vor wichtigen Operationen vollstÃ¤ndige Datenbank-Backups zu erstellen.

## ğŸ“ Support

Bei Problemen oder Fragen:
1. GitHub Issues verwenden
2. Logs prÃ¼fen fÃ¼r detaillierte Fehlermeldungen
3. Backup-Dateien fÃ¼r Wiederherstellung nutzen

---

ğŸ¤– *Entwickelt mit Claude Code fÃ¼r effiziente InfluxDB v1 Datenverwaltung*